{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2XwOLveXbCVd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6VDeFpea8zn"
      },
      "source": [
        "1. Problem Statement\n",
        "- This dataset comprises used cars sold on cardekho.com in India as well as important features of these cars.\n",
        "- User can predict the price of the car based on input features.\n",
        "- Prediction results can be used to give new seller the price suggestion based on market condition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdXs1IZla8zn"
      },
      "source": [
        "2. Data collection\n",
        "- Dataset is collected from scraping from cardekho website.\n",
        "- The data consists of 13 columns and 15411 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Purpose of the Dataset\n",
        "\n",
        "This dataset, collected from cardekho.com, comprises information on used cars sold in India. The primary purpose of this dataset and the predictive modeling task is:\n",
        "\n",
        " car aprice prediction: To predict the selling price of a used car based on various input features such as car name, brand, model, vehicle age, kilometers driven, seller type, fuel type, transmission type, mileage, engine size, maximum power, and number of seats.\n",
        "market proce suggestion: The prediction results can be utilized to provide new sellers with a data-driven price suggestion for their used cars, reflecting current market conditions and car attributes. This helps sellers to price their vehicles competitively and realistically."
      ],
      "metadata": {
        "id": "7RP11acWjuGo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7q952ypa8zo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iboCitcma8zo"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('cardekho_1csv.csv', index_col=0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf0hTgTCa8zp"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbEcdSN4a8zp"
      },
      "source": [
        "#### Data Cleaning\n",
        "- Handling Missing Values\n",
        "- Handling Duplicates\n",
        "- Check data type\n",
        "- Understand the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uHr1ar1a8zp"
      },
      "outputs": [],
      "source": [
        "# Check null values\n",
        "# Check features with nan value\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M20stcNqa8zq"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAql5Ubaa8zq"
      },
      "outputs": [],
      "source": [
        "## Remove unnecessary columns\n",
        "df.drop('car_name', axis=1, inplace=True)\n",
        "df.drop('brand', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDNNJRMMa8zq"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84F7gc1ta8zq"
      },
      "outputs": [],
      "source": [
        "df['model'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2tr_L-ma8zr"
      },
      "outputs": [],
      "source": [
        "# Getting all different types of features\n",
        "\n",
        "num_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
        "print('Number of numerical features: ', len(num_features))\n",
        "\n",
        "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
        "print('Number of categorical features: ', len(cat_features))\n",
        "\n",
        "discrete_features = [feature for feature in num_features if len(df[feature].unique()) < 25]\n",
        "print('Number of discrete features: ', len(discrete_features))\n",
        "\n",
        "continuous_features = [feature for feature in num_features if feature not in discrete_features]\n",
        "print('Number of continuous features: ', len(continuous_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeihiSmpa8zr"
      },
      "outputs": [],
      "source": [
        "## Independent and dependent features\n",
        "X = df.drop('selling_price', axis=1)\n",
        "y = df['selling_price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo-RUPr5a8zr"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B2TFPR8a8zr"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B7Jm1PHa8zr"
      },
      "source": [
        "##### **Feature Encoding and Scaling**\n",
        "**One Hot Encoding for Columns which had lesser unique values and not ordinal**\n",
        "- One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5_x3DRpa8zr"
      },
      "outputs": [],
      "source": [
        "df['model'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAHbtqxma8zr"
      },
      "outputs": [],
      "source": [
        "df['model'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn6eBjWma8zs"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X['model'] = le.fit_transform(X['model'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAHq34FUa8zs"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hJP8JfPa8zs"
      },
      "outputs": [],
      "source": [
        "len(df['seller_type'].unique()), len(df['fuel_type'].unique()), len(df['transmission_type'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Own3I4yDa8zs"
      },
      "outputs": [],
      "source": [
        "# Create ColumnTransformer with 3 types of transformers\n",
        "\n",
        "num_features = X.select_dtypes(exclude='object').columns\n",
        "onehot_columns = ['seller_type', 'fuel_type', 'transmission_type']\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "numeric_transformer = StandardScaler()\n",
        "oh_transformer = OneHotEncoder(drop='first')\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        ('OneHotEncoder', oh_transformer, onehot_columns),\n",
        "        ('StandardScaler', numeric_transformer, num_features)\n",
        "    ], remainder='passthrough'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56wjhk-ia8zs"
      },
      "outputs": [],
      "source": [
        "X = preprocessor.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwzBDYTia8zs"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz79xyBMa8zs"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(X).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTVVyYKHa8zs"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(X).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xUV3Ka7a8zs"
      },
      "outputs": [],
      "source": [
        "# Separa dataset into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGBZRy_la8zt"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEQ3jKmza8zt"
      },
      "outputs": [],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tcnf7Tia8zt"
      },
      "source": [
        "Model Training and Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThdZvGuQa8zt"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpqEP4a7a8zt"
      },
      "outputs": [],
      "source": [
        "## Create a function to evaluate the model\n",
        "def evaluate_model(true, predicted):\n",
        "    mae = mean_absolute_error(true, predicted)\n",
        "    mse = mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(true, predicted)\n",
        "    return mae, rmse, r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zKlrDza8zt"
      },
      "outputs": [],
      "source": [
        "## Beginning of model training\n",
        "\n",
        "models = {\n",
        "    'XGBRegressor': XGBRegressor(),\n",
        "}\n",
        "\n",
        "for i in range(len(list(models))):\n",
        "    model = list(models.values())[i]\n",
        "    model.fit(X_train, y_train) # Train the model\n",
        "\n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mae_train, rmse_train, r2_train = evaluate_model(y_train, y_train_pred)\n",
        "    mae_test, rmse_test, r2_test = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "    print(f'Model: {list(models.keys())[i]}')\n",
        "\n",
        "    print(\"Model Performance on Training Set\")\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(rmse_train))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(mae_train))\n",
        "    print(\"- R2 Score: {:.4f}\".format(r2_train))\n",
        "\n",
        "    print(\"-----------------------------------\")\n",
        "\n",
        "    print(\"Model Performance on Testing Set\")\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(rmse_test))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(mae_test))\n",
        "    print(\"- R2 Score: {:.4f}\".format(r2_test))\n",
        "\n",
        "    print('='*35)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vyN2TyMa8zt"
      },
      "outputs": [],
      "source": [
        " # Inilialize few parameters for hyperparameter tuning\n",
        "xb_params = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
        "    'max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'colsample_bytree': [0.3, 0.4, 0.5, 0.7, 1]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpGgihv1a8zt"
      },
      "outputs": [],
      "source": [
        "# Models list for hyperparameter tuning\n",
        "randomcv_models = [\n",
        "    ('XGBRegressor', XGBRegressor(), xb_params)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW_XzMs3a8zt"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "model_params = {}\n",
        "\n",
        "for name, model, params in randomcv_models:\n",
        "    random = RandomizedSearchCV(estimator=model,param_distributions=params, n_iter=100, cv=3, verbose=2,n_jobs=-1)\n",
        "    random.fit(X_train, y_train)\n",
        "    model_params[name] = random.best_params_\n",
        "\n",
        "for model_name in model_params:\n",
        "    print(f\"---------------------Best Parameters for {model_name}---------------------\")\n",
        "    print(model_params[model_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTETR9L6a8zu"
      },
      "outputs": [],
      "source": [
        "## Retrain the models with best parameters\n",
        "\n",
        "models = {\n",
        "    'XGBRegressor': XGBRegressor(learning_rate=0.2, max_depth=5, n_estimators=300, colsample_bytree=0.7),\n",
        "}\n",
        "\n",
        "for i in range(len(list(models))):\n",
        "    model = list(models.values())[i]\n",
        "    model.fit(X_train, y_train) # Train the model\n",
        "\n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mae_train, rmse_train, r2_train = evaluate_model(y_train, y_train_pred)\n",
        "    mae_test, rmse_test, r2_test = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "    print(f'Model: {list(models.keys())[i]}')\n",
        "\n",
        "    print(\"Model Performance on Training Set\")\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(rmse_train))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(mae_train))\n",
        "    print(\"- R2 Score: {:.4f}\".format(r2_train))\n",
        "\n",
        "    print(\"-----------------------------------\")\n",
        "\n",
        "    print(\"Model Performance on Testing Set\")\n",
        "    print(\"- Root Mean Squared Error: {:.4f}\".format(rmse_test))\n",
        "    print(\"- Mean Absolute Error: {:.4f}\".format(mae_test))\n",
        "    print(\"- R2 Score: {:.4f}\".format(r2_test))\n",
        "\n",
        "    print('='*35)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "162acf75"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "models = {\n",
        "\n",
        "    'SVR': SVR(),\n",
        "    'KNeighborsRegressor': KNeighborsRegressor()\n",
        "}\n",
        "\n",
        "print(\"Models dictionary created successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7474cbe1"
      },
      "source": [
        "model_results = {}\n",
        "\n",
        "for i in range(len(list(models))):\n",
        "    model_name = list(models.keys())[i]\n",
        "    model = list(models.values())[i]\n",
        "    model.fit(X_train, y_train) # Train the model\n",
        "\n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mae_train, rmse_train, r2_train = evaluate_model(y_train, y_train_pred)\n",
        "    mae_test, rmse_test, r2_test = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "    print(f'Model: {model_name}')\n",
        "\n",
        "    print(\"Model Performance on Training Set\")\n",
        "    print(f\"- Root Mean Squared Error: {rmse_train:.4f}\")\n",
        "    print(f\"- Mean Absolute Error: {mae_train:.4f}\")\n",
        "    print(f\"- R2 Score: {r2_train:.4f}\")\n",
        "\n",
        "    print(\"-----------------------------------\")\n",
        "\n",
        "    print(\"Model Performance on Testing Set\")\n",
        "    print(f\"- Root Mean Squared Error: {rmse_test:.4f}\")\n",
        "    print(f\"- Mean Absolute Error: {mae_test:.4f}\")\n",
        "    print(f\"- R2 Score: {r2_test:.4f}\")\n",
        "\n",
        "    print('='*35)\n",
        "    print('\\n')\n",
        "\n",
        "    model_results[model_name] = {\n",
        "        'train_rmse': rmse_train,\n",
        "        'train_mae': mae_train,\n",
        "        'train_r2': r2_train,\n",
        "        'test_rmse': rmse_test,\n",
        "        'test_mae': mae_test,\n",
        "        'test_r2': r2_test\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "961f8404"
      },
      "source": [
        "print(\"\\nSummary of Model Performance:\\n\")\n",
        "best_r2 = -float('inf')\n",
        "best_model = ''\n",
        "\n",
        "for model_name, metrics in model_results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"  Test RMSE: {metrics['test_rmse']:.4f}\")\n",
        "    print(f\"  Test MAE: {metrics['test_mae']:.4f}\")\n",
        "    print(f\"  Test R2 Score: {metrics['test_r2']:.4f}\")\n",
        "    print(\"-----------------------------------\")\n",
        "\n",
        "    if metrics['test_r2'] > best_r2:\n",
        "        best_r2 = metrics['test_r2']\n",
        "        best_model = model_name\n",
        "\n",
        "print(f\"\\nThe best performing model based on Test R2 Score is: {best_model} with R2 Score: {best_r2:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ae599ab"
      },
      "source": [
        "## Purpose of the Dataset\n",
        "\n",
        "This dataset, collected from cardekho.com, comprises information on used cars sold in India. The primary purpose of this dataset and the predictive modeling task is:\n",
        "\n",
        "*   **Car Price Prediction**: To predict the selling price of a used car based on various input features such as car name, brand, model, vehicle age, kilometers driven, seller type, fuel type, transmission type, mileage, engine size, maximum power, and number of seats.\n",
        "*   **Market Price Suggestion**: The prediction results can be utilized to provide new sellers with a data-driven price suggestion for their used cars, reflecting current market conditions and car attributes. This helps sellers to price their vehicles competitively and realistically."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}